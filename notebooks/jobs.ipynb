{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49e511c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763bfdf-9b99-4c9c-8614-7446a89504c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "path = '../src/'\n",
    "sys.path.append(path)\n",
    "\n",
    "from utils_nlp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79333498",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cfb2fc",
   "metadata": {},
   "source": [
    "Data available here:\n",
    "https://www.kaggle.com/datasets/narsil/jobs-in-data-com\n",
    "\n",
    "First download and save it into \"data\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6889b5-550f-420b-8193-fb689c13b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/job_descriptions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc48d9ac",
   "metadata": {},
   "source": [
    "# Feature Engineering and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['experience_list'] = df[\"Experience\"].apply(lambda x: [\n",
    "    float(i.strip()) for i in x.replace('Years', '').split('to')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55451d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_experience'] = df['experience_list'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_experience'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb255cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d71cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Work Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Country']=='USA']\n",
    "#df = df[df['Work Type']=='Full Time']\n",
    "#df = df[df['min_experience'].apply(lambda x: x<1.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca12d0",
   "metadata": {},
   "source": [
    "## Data Cleaning / Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean text applying all the text preprocessing functions\n",
    "df['cleaned_text'] = df['Job Description'].apply(\n",
    "    lambda x: ' '.join(preprocess_text(x))\n",
    "    )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191be75f",
   "metadata": {},
   "source": [
    "dict_of_tokens={i[1]:i[0] for i in vectorizer.vocabulary_.items()}\n",
    "tfidf_vectors = []  # all deoc vectors by tfidf\n",
    "for row in vectors:\n",
    "  tfidf_vectors.append(\n",
    "    {dict_of_tokens[column]:value for (column,value) in zip(row.indices,row.data)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['l_words']=df['cleaned_text'].apply(lambda x: list(set(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_salary'] = df[\"Salary Range\"].apply(lambda x: np.mean([\n",
    "    float(i.replace('$','').replace('K',''))*1000 for i in x.split('-')\n",
    "    ]))\n",
    "df['max_salary'] = df[\"Salary Range\"].apply(lambda x: np.max([\n",
    "    float(i.replace('$','').replace('K',''))*1000 for i in x.split('-')\n",
    "    ]))\n",
    "df['mean_experience'] = df[\"Experience\"].apply(lambda x: np.mean([\n",
    "    float(i.strip()) for i in x.replace('Years', '').split('to')\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2363369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.explode('l_words')\n",
    "df2 = df2.rename({\"l_words\":\"word\"}, axis = 1)\n",
    "df2['pos_tag'] =df2['word'].apply(lambda x: pos_tag([x],tagset='universal')[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea883990",
   "metadata": {},
   "source": [
    "## Filter only ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883debc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_adj = df2[df2[\"pos_tag\"]=='ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c391f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df2_adj.groupby('word').agg(\n",
    "    {'mean_experience': 'mean', \n",
    "     'max_salary': list,\n",
    "     'mean_salary': [list, \"count\"]\n",
    "     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db46503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_grouped.reset_index(col_level=0)\n",
    "df_grouped.columns = df_grouped.columns.droplevel(1)\n",
    "df_grouped.columns = ['word', 'mean_experience','max_salary', 'mean_salary', 'count']\n",
    "df_grouped.sort_values('count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped['median_salary']=df_grouped['mean_salary'].apply(lambda x: np.median(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c4bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.sort_values('count', ascending=False).iloc[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a0798",
   "metadata": {},
   "source": [
    "Select from the most common adjectives in the dataset sorted by median salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = df_grouped.sort_values('count', ascending=False).iloc[:15]\n",
    "selection = selection.sort_values('median_salary', ascending=True)\n",
    "words = list(selection['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ac40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ddab32",
   "metadata": {},
   "source": [
    "## Prepare some special fonts\n",
    "You may download FiraSans font from Google Fonts webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb28882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "personal_path = '../data/Fonts/'\n",
    "\n",
    "font_path = personal_path + 'FiraSans-Regular.ttf'\n",
    "fira_sans_regular = FontProperties(fname=font_path)\n",
    "\n",
    "font_path = personal_path + 'FiraSans-SemiBold.ttf'\n",
    "fira_sans_semibold = FontProperties(fname=font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=15, ncols=1, figsize=(8, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "variable = 'mean_salary'\n",
    "\n",
    "darkgreen = '#9BC184'\n",
    "midgreen = '#C2D6A4'\n",
    "lowgreen = '#E7E5CB'\n",
    "darkgrey = '#525252'\n",
    "\n",
    "pos_avg_experience = 60_000\n",
    "pos_words = 48_000\n",
    "x_min, x_max = 60_000, 125_000\n",
    "\n",
    "max_y = 0.00005\n",
    "colors = [lowgreen,midgreen,darkgreen,midgreen,lowgreen]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "\n",
    "    subset = df2_adj[df2_adj['word']==word]\n",
    "    \n",
    "    sns.kdeplot(subset[variable], \n",
    "                fill=True,\n",
    "                color = 'grey',\n",
    "                edgecolor='lightgrey',\n",
    "                ax=axs[i])\n",
    "    \n",
    "   \n",
    "    \"\"\" \n",
    "    # display average number of bedrooms on left\n",
    "    avg_experience = df_grouped[df_grouped['word']==word]['mean_experience'].values[0].round(1)\n",
    "    axs[i].text(\n",
    "        pos_avg_experience, 0,\n",
    "        f'({avg_experience})',\n",
    "        ha='left',\n",
    "        fontsize=10,\n",
    "        fontproperties=fira_sans_regular,\n",
    "        color=darkgrey\n",
    "    )\n",
    "    \"\"\" \n",
    "    # display word on left\n",
    "    axs[i].text(\n",
    "        pos_words, 0,\n",
    "        word.upper(),\n",
    "        ha='left',\n",
    "        fontsize=10,\n",
    "        fontproperties=fira_sans_semibold,\n",
    "        color=darkgrey\n",
    "    )\n",
    "\n",
    "    #quantiles\n",
    "    quantiles = np.percentile(subset[variable], [2.5, 10,25,75,90,97.5])\n",
    "    quantiles = quantiles.tolist()\n",
    "\n",
    "    for j in range(len(quantiles)-1):\n",
    "        axs[i].fill_between(\n",
    "            [quantiles[j],\n",
    "              quantiles[j+1]], \n",
    "                0,\n",
    "                max_y/5,\n",
    "                color = colors[j]\n",
    "                )\n",
    "        \n",
    "    median = subset[variable].median()\n",
    "    axs[i].scatter([median], [max_y/10], color='black', s=20)\n",
    "            \n",
    "    global_median = df[variable].median()\n",
    "    axs[i].axvline(global_median, color='red', linestyle='--')\n",
    "\n",
    "    axs[i].set_xlim(x_min, x_max)\n",
    "    axs[i].set_ylim(0,max_y)\n",
    "    axs[i].set_ylabel(\"\")\n",
    "\n",
    "    axs[i].set_axis_off()\n",
    "    # x axis scale for last ax\n",
    "    if i == 14:\n",
    "        values = [70_000, 80_000, 90_000, 100_000]\n",
    "        for value in values:\n",
    "            axs[i].text(\n",
    "                value, -0.00003,\n",
    "                f'{value}',\n",
    "                ha='center',\n",
    "                fontsize=10\n",
    "            )\n",
    "        axs[i].set_xlabel('Salary')\n",
    "        axs[i].set_xticks(values)\n",
    "\n",
    "    \n",
    "\"\"\"   \n",
    "text = '(Avg. Experience)'\n",
    "fig.text(\n",
    "    0.06,\n",
    "    0.88,\n",
    "    text,\n",
    "    ha='left',\n",
    "    fontsize=10,\n",
    "    fontproperties=fira_sans_regular,\n",
    "    color=darkgrey\n",
    ")\n",
    "\"\"\" \n",
    "# x axis label\n",
    "text = \"Annual Gross Salary (USD)\"\n",
    "fig.text(\n",
    "    0.5, 0.06,\n",
    "    text,\n",
    "    ha='center',\n",
    "    fontsize=14,\n",
    "    fontproperties=fira_sans_regular\n",
    ")\n",
    "\n",
    "\n",
    "text = 'Global Median Salary'\n",
    "fig.text(0.5, 0.88, text,color='r', ha='center', fontsize=10)\n",
    "\n",
    "# title\n",
    "text = \"STRATEGIC and VARIOUS equal to UNDER PAID?\"\n",
    "fig.text(\n",
    "    -0.03, 1.01,\n",
    "    text,\n",
    "    ha='left',\n",
    "    fontsize=18,\n",
    "    fontproperties=fira_sans_semibold\n",
    ")\n",
    "text = \"\"\"\n",
    "Adjectives used to describe jobs and how they are related to Salaries.\n",
    "Job Description from jobs found in Kaggle Dataset, filtering for USA.\n",
    "The 15 most frequent adjectives are shown.\n",
    "\"\"\"\n",
    "fig.text(\n",
    "    -0.03, 0.9,\n",
    "    text,\n",
    "    ha='left',\n",
    "    fontsize=14,\n",
    "    fontproperties=fira_sans_regular\n",
    ")\n",
    "# credit\n",
    "text = \"\"\"\n",
    "Axis capped at 100,000 USD.\n",
    "Data: https://www.kaggle.com/datasets/hummaamqaasim/jobs-in-data. \n",
    "Visualization: Toni Almagro (lessdatamorestories.com) \n",
    "based on https://python-graph-gallery.com/web-ridgeline-by-text/ \n",
    "\"\"\"\n",
    "fig.text(\n",
    "    -0.03, -0.03,\n",
    "    text,\n",
    "    ha='left',\n",
    "    fontsize=8,\n",
    "    fontproperties=fira_sans_regular\n",
    ")\n",
    "\n",
    "#Explanation\n",
    "## ---------------\n",
    "\n",
    "# legend on the first ax\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "subax = inset_axes(\n",
    "    parent_axes=axs[0],\n",
    "    width=\"40%\",\n",
    "    height=\"350%\",\n",
    "    loc=1\n",
    ")\n",
    "subax.set_xticks([])\n",
    "subax.set_yticks([])\n",
    "beautiful_subset = df2_adj[df2_adj['word']=='overall']\n",
    "\n",
    "sns.kdeplot(\n",
    "    beautiful_subset[variable],\n",
    "    fill=True,\n",
    "    ax=subax,\n",
    "    color='grey',\n",
    "    edgecolor='lightgrey'\n",
    ")\n",
    "quantiles = np.percentile(beautiful_subset[variable], [2.5, 10, 25, 75, 90, 97.5])\n",
    "quantiles = quantiles.tolist()\n",
    "for j in range(len(quantiles) - 1):\n",
    "    subax.fill_between(\n",
    "        [quantiles[j], # lower bound\n",
    "         quantiles[j+1]], # upper bound\n",
    "        0, # max y=0\n",
    "        max_y/10, # max y=0.00004\n",
    "        color=colors[j]\n",
    "    )\n",
    "subax.set_xlim(x_min, x_max-20_000)\n",
    "subax.set_ylim(-0.00002, max_y)\n",
    "mean = beautiful_subset[variable].median()\n",
    "subax.scatter([mean], [0.0000025], color='black', s=20)\n",
    "\n",
    "legend_pos = 0.000055\n",
    "subax.text(\n",
    "    x_min+5000, legend_pos,\n",
    "    'Explanation',\n",
    "    ha='left',\n",
    "    fontsize=12,\n",
    "    fontproperties=fira_sans_semibold\n",
    ")\n",
    "\n",
    "subax.text(\n",
    "    x_max-30_000, legend_pos/2,\n",
    "    'Distribution\\nof Salaries',\n",
    "    ha='center',\n",
    "    fontsize=7,\n",
    "    fontproperties=fira_sans_regular\n",
    ")\n",
    "subax.text(\n",
    "    mean, legend_pos/4,\n",
    "    'Median',\n",
    "    ha='center',\n",
    "    fontsize=7,\n",
    "    fontproperties=fira_sans_regular\n",
    ")\n",
    "\n",
    "subtext_pos = -0.00001\n",
    "subax.text(\n",
    "    quantiles[4]+5_000,subtext_pos*1.5,\n",
    "    \"95% of salaries\",\n",
    "    ha='center',\n",
    "    fontsize=6,\n",
    "    fontproperties=fira_sans_regular\n",
    ")\n",
    "\n",
    "subax.text(\n",
    "    quantiles[3],subtext_pos,\n",
    "    \"80% of salaries\",\n",
    "    ha='center',\n",
    "    fontsize=6,\n",
    "    fontproperties=fira_sans_regular\n",
    ")\n",
    "subax.text(\n",
    "    quantiles[1], subtext_pos*1.5,\n",
    "    \"50% of salaries\\nfall within this range\",\n",
    "    ha='center',\n",
    "    fontsize=6,\n",
    "    fontproperties=fira_sans_regular\n",
    ")\n",
    "\n",
    "# arrows in the legend\n",
    "import matplotlib.patches as patches\n",
    "def add_arrow(head_pos, tail_pos, ax):\n",
    "    style = \"Simple, tail_width=0.01, head_width=1, head_length=2\"\n",
    "    kw = dict(arrowstyle=style, color=\"k\", linewidth=0.2)\n",
    "    arrow = patches.FancyArrowPatch(\n",
    "        tail_pos, head_pos,\n",
    "        connectionstyle=\"arc3,rad=.5\",\n",
    "        **kw\n",
    "    )\n",
    "    ax.add_patch(arrow)\n",
    "add_arrow( (mean-3_000, 0.000005),(quantiles[1]+5000, subtext_pos*1.2), subax) # 50%\n",
    "add_arrow( (quantiles[3]+2000,0.0000025), (quantiles[3], -0.0000055),subax) # 80%\n",
    "add_arrow((mean, 0.000005), (mean, 0.000015), subax) #,median \n",
    "add_arrow((quantiles[4]+1000, 0.000003), (quantiles[4]+5_000,subtext_pos), subax) # 50%\n",
    "\n",
    "# background grey lines\n",
    "from matplotlib.lines import Line2D\n",
    "def add_line(xpos, ypos, fig=fig):\n",
    "    line = Line2D(\n",
    "        xpos, ypos,\n",
    "        color='lightgrey',\n",
    "        lw=0.2,\n",
    "        transform=fig.transFigure\n",
    "    )\n",
    "    fig.lines.append(line)\n",
    "#add_line([0.317, 0.317], [0.1, 0.9])\n",
    "#add_line([0.51, 0.51], [0.1, 0.9])\n",
    "#add_line([0.703, 0.703], [0.1, 0.9])\n",
    "#add_line([0.896, 0.896], [0.1, 0.9])\n",
    "\n",
    "plt.savefig('../images/jobs-ridgeline-by-text-USA.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
